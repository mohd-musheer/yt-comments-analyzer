{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":4140,"sourceType":"datasetVersion","datasetId":2477},{"sourceId":14750463,"sourceType":"datasetVersion","datasetId":9427305}],"dockerImageVersionId":31259,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport re\n\n\nfrom sklearn.metrics import accuracy_score\nimport joblib","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-09T17:21:32.423872Z","iopub.execute_input":"2026-02-09T17:21:32.424168Z","iopub.status.idle":"2026-02-09T17:21:34.809391Z","shell.execute_reply.started":"2026-02-09T17:21:32.424139Z","shell.execute_reply":"2026-02-09T17:21:34.808595Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"columns = ['target', 'id', 'date', 'query', 'user', 'text']\n\ndf = pd.read_csv(\n    '/kaggle/input/sentiment140/training.1600000.processed.noemoticon.csv',\n    encoding='latin-1',\n    names=columns\n)\n\ndf.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-09T17:21:34.810974Z","iopub.execute_input":"2026-02-09T17:21:34.811443Z","iopub.status.idle":"2026-02-09T17:21:40.216640Z","shell.execute_reply.started":"2026-02-09T17:21:34.811417Z","shell.execute_reply":"2026-02-09T17:21:40.215880Z"}},"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"   target          id                          date     query  \\\n0       0  1467810369  Mon Apr 06 22:19:45 PDT 2009  NO_QUERY   \n1       0  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY   \n2       0  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY   \n3       0  1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n4       0  1467811193  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n\n              user                                               text  \n0  _TheSpecialOne_  @switchfoot http://twitpic.com/2y1zl - Awww, t...  \n1    scotthamilton  is upset that he can't update his Facebook by ...  \n2         mattycus  @Kenichan I dived many times for the ball. Man...  \n3          ElleCTF    my whole body feels itchy and like its on fire   \n4           Karoli  @nationwideclass no, it's not behaving at all....  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>target</th>\n      <th>id</th>\n      <th>date</th>\n      <th>query</th>\n      <th>user</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>1467810369</td>\n      <td>Mon Apr 06 22:19:45 PDT 2009</td>\n      <td>NO_QUERY</td>\n      <td>_TheSpecialOne_</td>\n      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>1467810672</td>\n      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n      <td>NO_QUERY</td>\n      <td>scotthamilton</td>\n      <td>is upset that he can't update his Facebook by ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>1467810917</td>\n      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n      <td>NO_QUERY</td>\n      <td>mattycus</td>\n      <td>@Kenichan I dived many times for the ball. Man...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>1467811184</td>\n      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n      <td>NO_QUERY</td>\n      <td>ElleCTF</td>\n      <td>my whole body feels itchy and like its on fire</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>1467811193</td>\n      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n      <td>NO_QUERY</td>\n      <td>Karoli</td>\n      <td>@nationwideclass no, it's not behaving at all....</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":2},{"cell_type":"code","source":"len(df)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-09T17:21:40.217705Z","iopub.execute_input":"2026-02-09T17:21:40.217957Z","iopub.status.idle":"2026-02-09T17:21:40.222852Z","shell.execute_reply.started":"2026-02-09T17:21:40.217934Z","shell.execute_reply":"2026-02-09T17:21:40.222148Z"}},"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"1600000"},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"def clean_tweet(text):\n  text = text.lower()\n  text = re.sub(r'http\\S+', '', text)\n  text = re.sub(r'@\\S+', '', text)\n\n  return text.strip()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-09T17:21:40.223892Z","iopub.execute_input":"2026-02-09T17:21:40.224352Z","iopub.status.idle":"2026-02-09T17:21:40.234387Z","shell.execute_reply.started":"2026-02-09T17:21:40.224310Z","shell.execute_reply":"2026-02-09T17:21:40.233612Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"df['clean_text'] = df['text'].apply(clean_tweet)\ndf.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-09T17:21:40.236197Z","iopub.execute_input":"2026-02-09T17:21:40.236816Z","iopub.status.idle":"2026-02-09T17:21:43.138877Z","shell.execute_reply.started":"2026-02-09T17:21:40.236792Z","shell.execute_reply":"2026-02-09T17:21:43.138155Z"}},"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"   target          id                          date     query  \\\n0       0  1467810369  Mon Apr 06 22:19:45 PDT 2009  NO_QUERY   \n1       0  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY   \n2       0  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY   \n3       0  1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n4       0  1467811193  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n\n              user                                               text  \\\n0  _TheSpecialOne_  @switchfoot http://twitpic.com/2y1zl - Awww, t...   \n1    scotthamilton  is upset that he can't update his Facebook by ...   \n2         mattycus  @Kenichan I dived many times for the ball. Man...   \n3          ElleCTF    my whole body feels itchy and like its on fire    \n4           Karoli  @nationwideclass no, it's not behaving at all....   \n\n                                          clean_text  \n0  - awww, that's a bummer.  you shoulda got davi...  \n1  is upset that he can't update his facebook by ...  \n2  i dived many times for the ball. managed to sa...  \n3     my whole body feels itchy and like its on fire  \n4  no, it's not behaving at all. i'm mad. why am ...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>target</th>\n      <th>id</th>\n      <th>date</th>\n      <th>query</th>\n      <th>user</th>\n      <th>text</th>\n      <th>clean_text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>1467810369</td>\n      <td>Mon Apr 06 22:19:45 PDT 2009</td>\n      <td>NO_QUERY</td>\n      <td>_TheSpecialOne_</td>\n      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n      <td>- awww, that's a bummer.  you shoulda got davi...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>1467810672</td>\n      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n      <td>NO_QUERY</td>\n      <td>scotthamilton</td>\n      <td>is upset that he can't update his Facebook by ...</td>\n      <td>is upset that he can't update his facebook by ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>1467810917</td>\n      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n      <td>NO_QUERY</td>\n      <td>mattycus</td>\n      <td>@Kenichan I dived many times for the ball. Man...</td>\n      <td>i dived many times for the ball. managed to sa...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>1467811184</td>\n      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n      <td>NO_QUERY</td>\n      <td>ElleCTF</td>\n      <td>my whole body feels itchy and like its on fire</td>\n      <td>my whole body feels itchy and like its on fire</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>1467811193</td>\n      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n      <td>NO_QUERY</td>\n      <td>Karoli</td>\n      <td>@nationwideclass no, it's not behaving at all....</td>\n      <td>no, it's not behaving at all. i'm mad. why am ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"df.isna().sum()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-09T17:21:43.140117Z","iopub.execute_input":"2026-02-09T17:21:43.140498Z","iopub.status.idle":"2026-02-09T17:21:43.547388Z","shell.execute_reply.started":"2026-02-09T17:21:43.140459Z","shell.execute_reply":"2026-02-09T17:21:43.546759Z"}},"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"target        0\nid            0\ndate          0\nquery         0\nuser          0\ntext          0\nclean_text    0\ndtype: int64"},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"# Original Dataset\nfrom sklearn.model_selection import train_test_split\n\ndef split(df):\n    TRAIN_SIZE = 0.70\n    TEST_SIZE = 0.15\n    VAL_SIZE = 0.15\n    \n    train_val, test_df = train_test_split(df, test_size=TEST_SIZE, random_state=42, stratify = df['target'])\n    \n    adjusted_val_size = VAL_SIZE/(TRAIN_SIZE+VAL_SIZE)\n    \n    train_df, val_df = train_test_split(train_val, test_size=adjusted_val_size, random_state=42, stratify = train_val['target'])\n    \n    print(f\"  Total samples: {len(df):,}\")\n    print(f\"  Training:   {len(train_df):,} ({len(train_df)/len(df)*100:.1f}%)\")\n    print(f\"  Validation: {len(val_df):,} ({len(val_df)/len(df)*100:.1f}%)\")\n    print(f\"  Test:       {len(test_df):,} ({len(test_df)/len(df)*100:.1f}%)\")\n\n    return train_df, test_df, val_df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-09T17:21:43.548294Z","iopub.execute_input":"2026-02-09T17:21:43.548598Z","iopub.status.idle":"2026-02-09T17:21:43.569764Z","shell.execute_reply.started":"2026-02-09T17:21:43.548576Z","shell.execute_reply":"2026-02-09T17:21:43.569051Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"print('Splitting Original Dataset')\ntrain_df, test_df, val_df = split(df)\n# print('\\nSplitting Scaled Dataset')\n# train_df_scaled, test_df_scaled, val_df_scaled = split(df_scaled)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-09T17:21:43.573194Z","iopub.execute_input":"2026-02-09T17:21:43.573391Z","iopub.status.idle":"2026-02-09T17:21:47.002998Z","shell.execute_reply.started":"2026-02-09T17:21:43.573369Z","shell.execute_reply":"2026-02-09T17:21:47.002101Z"}},"outputs":[{"name":"stdout","text":"Splitting Original Dataset\n  Total samples: 1,600,000\n  Training:   1,119,999 (70.0%)\n  Validation: 240,001 (15.0%)\n  Test:       240,000 (15.0%)\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"X_train = train_df['clean_text']\ny_train = train_df['target']\n\nX_val = val_df['clean_text']\ny_val = val_df['target']\n\n# X_train_scaled = train_df_scaled['clean_text']\n# y_train_scaled = train_df_scaled['target']\n\n# X_val_scaled = val_df_scaled['clean_text']\n# y_val_scaled = val_df_scaled['target']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-09T17:21:52.850365Z","iopub.execute_input":"2026-02-09T17:21:52.850962Z","iopub.status.idle":"2026-02-09T17:21:52.855113Z","shell.execute_reply.started":"2026-02-09T17:21:52.850934Z","shell.execute_reply":"2026-02-09T17:21:52.854372Z"}},"outputs":[],"execution_count":9},{"cell_type":"markdown","source":"## Classical ML","metadata":{}},{"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.svm import LinearSVC\nfrom sklearn.feature_extraction.text import TfidfVectorizer","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-09T17:21:58.554308Z","iopub.execute_input":"2026-02-09T17:21:58.555114Z","iopub.status.idle":"2026-02-09T17:21:58.655733Z","shell.execute_reply.started":"2026-02-09T17:21:58.555084Z","shell.execute_reply":"2026-02-09T17:21:58.655129Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"models = {\n    \"Naive Bayes\": MultinomialNB(),\n    \"Logistic Regression\": LogisticRegression(max_iter=1000, n_jobs=-1),\n    \"Linear SVM\": LinearSVC() \n}\n\nvectorizer = TfidfVectorizer(max_features=100000, ngram_range=(1,2))\nprint(\"Vectorizing Oringal Dataset\")\nX_train = vectorizer.fit_transform(X_train)\nX_val = vectorizer.transform(X_val)\n\n# print(\"Vectorizing Scaled Dataset\")\n# X_train_scaled = vectorizer.fit_transform(X_train_scaled)\n# X_val_scaled = vectorizer.transform(X_val_scaled)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-09T17:22:04.696658Z","iopub.execute_input":"2026-02-09T17:22:04.697355Z","iopub.status.idle":"2026-02-09T17:22:46.570397Z","shell.execute_reply.started":"2026-02-09T17:22:04.697329Z","shell.execute_reply":"2026-02-09T17:22:46.569723Z"}},"outputs":[{"name":"stdout","text":"Vectorizing Oringal Dataset\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score, precision_recall_fscore_support, classification_report, confusion_matrix\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\ndef evaluate_metrics(y_val, y_pred, model_name=\"Model\"):\n    print(f\"\\nEvaluation for {model_name}\")\n    \n    acc = accuracy_score(y_val, y_pred)\n    precision, recall, f1, _ = precision_recall_fscore_support(y_val, y_pred, average='weighted')\n    \n    print(f\"Accuracy:  {acc:.4f}\")\n    print(f\"Precision: {precision:.4f}\")\n    print(f\"Recall:    {recall:.4f}\")\n    print(f\"F1 Score:  {f1:.4f}\")\n    \n    # 2. Detailed Report\n    print(classification_report(y_val, y_pred))\n    cm = confusion_matrix(y_val, y_pred)\n    \n    return {\"accuracy\": acc, \"f1\": f1, \"precision\": precision, \"recall\": recall, \"cm\": cm}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-09T17:22:46.571628Z","iopub.execute_input":"2026-02-09T17:22:46.571945Z","iopub.status.idle":"2026-02-09T17:22:46.919730Z","shell.execute_reply.started":"2026-02-09T17:22:46.571907Z","shell.execute_reply":"2026-02-09T17:22:46.919060Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"def finetune(models, X_train, y_train, X_val, y_val):\n    results = {}\n    \n    for name, model in models.items():\n        print(f\"----Training {name}----\")\n        model.fit(X_train, y_train)\n        preds = model.predict(X_val)\n        metrics = evaluate_metrics(y_val, preds, model_name=name)\n        results[name] = metrics\n        \n    return results","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-09T17:22:46.920805Z","iopub.execute_input":"2026-02-09T17:22:46.921236Z","iopub.status.idle":"2026-02-09T17:22:46.925613Z","shell.execute_reply.started":"2026-02-09T17:22:46.921209Z","shell.execute_reply":"2026-02-09T17:22:46.924836Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"print('---Fine-Tuning On Original Dataset---')\nresults = finetune(models, X_train, y_train, X_val, y_val)\n# print('---Fine-Tuning On Scaled Dataset---')\n# results_scaled = finetune(models, X_train_scaled, y_train_scaled, X_val_scaled, y_val_scaled)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-09T17:22:46.927463Z","iopub.execute_input":"2026-02-09T17:22:46.927757Z","iopub.status.idle":"2026-02-09T17:23:53.523238Z","shell.execute_reply.started":"2026-02-09T17:22:46.927735Z","shell.execute_reply":"2026-02-09T17:23:53.522329Z"}},"outputs":[{"name":"stdout","text":"---Fine-Tuning On Original Dataset---\n----Training Naive Bayes----\n\nEvaluation for Naive Bayes\nAccuracy:  0.7994\nPrecision: 0.7995\nRecall:    0.7994\nF1 Score:  0.7994\n              precision    recall  f1-score   support\n\n           0       0.80      0.80      0.80    120001\n           4       0.80      0.79      0.80    120000\n\n    accuracy                           0.80    240001\n   macro avg       0.80      0.80      0.80    240001\nweighted avg       0.80      0.80      0.80    240001\n\n----Training Logistic Regression----\n\nEvaluation for Logistic Regression\nAccuracy:  0.8195\nPrecision: 0.8196\nRecall:    0.8195\nF1 Score:  0.8194\n              precision    recall  f1-score   support\n\n           0       0.83      0.81      0.82    120001\n           4       0.81      0.83      0.82    120000\n\n    accuracy                           0.82    240001\n   macro avg       0.82      0.82      0.82    240001\nweighted avg       0.82      0.82      0.82    240001\n\n----Training Linear SVM----\n\nEvaluation for Linear SVM\nAccuracy:  0.8148\nPrecision: 0.8150\nRecall:    0.8148\nF1 Score:  0.8148\n              precision    recall  f1-score   support\n\n           0       0.82      0.80      0.81    120001\n           4       0.81      0.83      0.82    120000\n\n    accuracy                           0.81    240001\n   macro avg       0.81      0.81      0.81    240001\nweighted avg       0.81      0.81      0.81    240001\n\n","output_type":"stream"}],"execution_count":14},{"cell_type":"markdown","source":"## DistilBert","metadata":{}},{"cell_type":"code","source":"!pip install ipywidgets\n!jupyter nbextension enable --py widgetsnbextension\n!pip install optimum[onnxruntime]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-09T17:23:53.524401Z","iopub.execute_input":"2026-02-09T17:23:53.524786Z","iopub.status.idle":"2026-02-09T17:24:04.241286Z","shell.execute_reply.started":"2026-02-09T17:23:53.524750Z","shell.execute_reply":"2026-02-09T17:24:04.240466Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: ipywidgets in /usr/local/lib/python3.12/dist-packages (8.1.5)\nRequirement already satisfied: comm>=0.1.3 in /usr/local/lib/python3.12/dist-packages (from ipywidgets) (0.2.3)\nRequirement already satisfied: ipython>=6.1.0 in /usr/local/lib/python3.12/dist-packages (from ipywidgets) (7.34.0)\nRequirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.12/dist-packages (from ipywidgets) (5.7.1)\nRequirement already satisfied: widgetsnbextension~=4.0.12 in /usr/local/lib/python3.12/dist-packages (from ipywidgets) (4.0.15)\nRequirement already satisfied: jupyterlab-widgets~=3.0.12 in /usr/local/lib/python3.12/dist-packages (from ipywidgets) (3.0.15)\nRequirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.12/dist-packages (from ipython>=6.1.0->ipywidgets) (75.2.0)\nRequirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.12/dist-packages (from ipython>=6.1.0->ipywidgets) (0.19.2)\nRequirement already satisfied: decorator in /usr/local/lib/python3.12/dist-packages (from ipython>=6.1.0->ipywidgets) (4.4.2)\nRequirement already satisfied: pickleshare in /usr/local/lib/python3.12/dist-packages (from ipython>=6.1.0->ipywidgets) (0.7.5)\nRequirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from ipython>=6.1.0->ipywidgets) (3.0.52)\nRequirement already satisfied: pygments in /usr/local/lib/python3.12/dist-packages (from ipython>=6.1.0->ipywidgets) (2.19.2)\nRequirement already satisfied: backcall in /usr/local/lib/python3.12/dist-packages (from ipython>=6.1.0->ipywidgets) (0.2.0)\nRequirement already satisfied: matplotlib-inline in /usr/local/lib/python3.12/dist-packages (from ipython>=6.1.0->ipywidgets) (0.1.7)\nRequirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.12/dist-packages (from ipython>=6.1.0->ipywidgets) (4.9.0)\nRequirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.12/dist-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.5)\nRequirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.12/dist-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\nRequirement already satisfied: wcwidth in /usr/local/lib/python3.12/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=6.1.0->ipywidgets) (0.2.14)\nEnabling notebook extension jupyter-js-widgets/extension...\n      - Validating: \u001b[32mOK\u001b[0m\nCollecting optimum[onnxruntime]\n  Downloading optimum-2.1.0-py3-none-any.whl.metadata (14 kB)\nRequirement already satisfied: transformers>=4.29 in /usr/local/lib/python3.12/dist-packages (from optimum[onnxruntime]) (4.57.1)\nRequirement already satisfied: torch>=1.11 in /usr/local/lib/python3.12/dist-packages (from optimum[onnxruntime]) (2.8.0+cu126)\nRequirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from optimum[onnxruntime]) (26.0rc2)\nRequirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from optimum[onnxruntime]) (2.0.2)\nRequirement already satisfied: huggingface_hub>=0.8.0 in /usr/local/lib/python3.12/dist-packages (from optimum[onnxruntime]) (0.36.0)\nCollecting optimum-onnx[onnxruntime] (from optimum[onnxruntime])\n  Downloading optimum_onnx-0.1.0-py3-none-any.whl.metadata (4.8 kB)\nRequirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.8.0->optimum[onnxruntime]) (3.20.3)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.8.0->optimum[onnxruntime]) (2025.10.0)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.8.0->optimum[onnxruntime]) (6.0.3)\nRequirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.8.0->optimum[onnxruntime]) (2.32.5)\nRequirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.8.0->optimum[onnxruntime]) (4.67.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.8.0->optimum[onnxruntime]) (4.15.0)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.8.0->optimum[onnxruntime]) (1.2.1rc0)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.11->optimum[onnxruntime]) (75.2.0)\nRequirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11->optimum[onnxruntime]) (1.13.3)\nRequirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=1.11->optimum[onnxruntime]) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11->optimum[onnxruntime]) (3.1.6)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11->optimum[onnxruntime]) (12.6.77)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11->optimum[onnxruntime]) (12.6.77)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11->optimum[onnxruntime]) (12.6.80)\nRequirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11->optimum[onnxruntime]) (9.10.2.21)\nRequirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11->optimum[onnxruntime]) (12.6.4.1)\nRequirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11->optimum[onnxruntime]) (11.3.0.4)\nRequirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11->optimum[onnxruntime]) (10.3.7.77)\nRequirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11->optimum[onnxruntime]) (11.7.1.2)\nRequirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11->optimum[onnxruntime]) (12.5.4.2)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11->optimum[onnxruntime]) (0.7.1)\nRequirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11->optimum[onnxruntime]) (2.27.3)\nRequirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11->optimum[onnxruntime]) (12.6.77)\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11->optimum[onnxruntime]) (12.6.85)\nRequirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11->optimum[onnxruntime]) (1.11.1.6)\nRequirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11->optimum[onnxruntime]) (3.4.0)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.29->optimum[onnxruntime]) (2025.11.3)\nRequirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.29->optimum[onnxruntime]) (0.22.1)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.29->optimum[onnxruntime]) (0.6.2)\nRequirement already satisfied: onnx in /usr/local/lib/python3.12/dist-packages (from optimum-onnx[onnxruntime]; extra == \"onnxruntime\"->optimum[onnxruntime]) (1.20.1)\nCollecting onnxruntime>=1.18.0 (from optimum-onnx[onnxruntime]; extra == \"onnxruntime\"->optimum[onnxruntime])\n  Downloading onnxruntime-1.24.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.9 kB)\nRequirement already satisfied: flatbuffers in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.18.0->optimum-onnx[onnxruntime]; extra == \"onnxruntime\"->optimum[onnxruntime]) (25.9.23)\nRequirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.18.0->optimum-onnx[onnxruntime]; extra == \"onnxruntime\"->optimum[onnxruntime]) (5.29.5)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.11->optimum[onnxruntime]) (1.3.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.11->optimum[onnxruntime]) (3.0.3)\nRequirement already satisfied: ml_dtypes>=0.5.0 in /usr/local/lib/python3.12/dist-packages (from onnx->optimum-onnx[onnxruntime]; extra == \"onnxruntime\"->optimum[onnxruntime]) (0.5.3)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub>=0.8.0->optimum[onnxruntime]) (3.4.4)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub>=0.8.0->optimum[onnxruntime]) (3.11)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub>=0.8.0->optimum[onnxruntime]) (2.6.3)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub>=0.8.0->optimum[onnxruntime]) (2026.1.4)\nDownloading optimum-2.1.0-py3-none-any.whl (161 kB)\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m161.2/161.2 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading onnxruntime-1.24.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (17.1 MB)\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m17.1/17.1 MB\u001b[0m \u001b[31m89.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hDownloading optimum_onnx-0.1.0-py3-none-any.whl (194 kB)\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m194.2/194.2 kB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: onnxruntime, optimum, optimum-onnx\nSuccessfully installed onnxruntime-1.24.1 optimum-2.1.0 optimum-onnx-0.1.0\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"from tqdm.auto import tqdm\nfrom datasets import Dataset\nfrom transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-09T17:24:04.242596Z","iopub.execute_input":"2026-02-09T17:24:04.242945Z","iopub.status.idle":"2026-02-09T17:24:37.109098Z","shell.execute_reply.started":"2026-02-09T17:24:04.242895Z","shell.execute_reply":"2026-02-09T17:24:37.108466Z"}},"outputs":[{"name":"stderr","text":"2026-02-09 17:24:19.549722: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1770657859.758660      55 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1770657859.816440      55 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nW0000 00:00:1770657860.324664      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1770657860.324718      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1770657860.324724      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1770657860.324726      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"model_checkpoint = \"distilbert-base-uncased\"\nbatch_size = 64\nmax_length = 64","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-09T17:24:37.110050Z","iopub.execute_input":"2026-02-09T17:24:37.110699Z","iopub.status.idle":"2026-02-09T17:24:37.114649Z","shell.execute_reply.started":"2026-02-09T17:24:37.110671Z","shell.execute_reply":"2026-02-09T17:24:37.113735Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"def clean_tweet_for_bert(text):\n    text = str(text).lower()                   \n    text = re.sub(r'@[A-Za-z0-9_]+', '', text) \n    text = re.sub(r'http\\S+', '', text)        \n    text = \" \".join(text.split())\n    return text.strip()\n\ndf['clean_text_bert'] = df['text'].apply(clean_tweet_for_bert)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-09T17:24:37.115911Z","iopub.execute_input":"2026-02-09T17:24:37.116735Z","iopub.status.idle":"2026-02-09T17:24:42.172755Z","shell.execute_reply.started":"2026-02-09T17:24:37.116690Z","shell.execute_reply":"2026-02-09T17:24:42.171978Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"from datasets import Dataset\n\ndef create_hf_dataset(df, text_col='clean_text', target_col='target'):\n    target_map = {0: 0, 4: 1}\n\n    df_processed = df.copy()\n    df_processed['label'] = df_processed[target_col].map(target_map)\n    \n    df_processed = df_processed[[text_col, 'label']]\n    \n    return Dataset.from_pandas(df_processed)\n\ntrain_dataset = create_hf_dataset(train_df)\nval_dataset   = create_hf_dataset(val_df)\n\n# train_dataset_scaled = create_hf_dataset(train_df_scaled)\n# val_dataset_scaled   = create_hf_dataset(val_df_scaled)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-09T17:24:42.173782Z","iopub.execute_input":"2026-02-09T17:24:42.174050Z","iopub.status.idle":"2026-02-09T17:24:44.498386Z","shell.execute_reply.started":"2026-02-09T17:24:42.174025Z","shell.execute_reply":"2026-02-09T17:24:44.497218Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_55/1334128685.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mval_dataset\u001b[0m   \u001b[0;34m=\u001b[0m \u001b[0mcreate_hf_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mtrain_dataset_scaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_hf_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_df_scaled\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0mval_dataset_scaled\u001b[0m   \u001b[0;34m=\u001b[0m \u001b[0mcreate_hf_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_df_scaled\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'train_df_scaled' is not defined"],"ename":"NameError","evalue":"name 'train_df_scaled' is not defined","output_type":"error"}],"execution_count":19},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n\ndef preprocess_function(examples):\n    return tokenizer(examples[\"clean_text\"], truncation=True, padding=\"max_length\", max_length=max_length)\n\nprint(\"Tokenizing Original Data...\")\nencoded_train = train_dataset.map(preprocess_function, batched=True, desc=\"Tokenizing Train\")\nencoded_val = val_dataset.map(preprocess_function, batched=True, desc=\"Tokenizing Val\")\n\n# print(\"Tokenizing Scaled Data...\")\n# encoded_train_scaled = train_dataset_scaled.map(preprocess_function, batched=True, desc=\"Tokenizing Train\")\n# encoded_val_scaled = val_dataset_scaled.map(preprocess_function, batched=True, desc=\"Tokenizing Val\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-09T17:27:39.240864Z","iopub.execute_input":"2026-02-09T17:27:39.241681Z","iopub.status.idle":"2026-02-09T17:29:13.387938Z","shell.execute_reply.started":"2026-02-09T17:27:39.241651Z","shell.execute_reply":"2026-02-09T17:29:13.387086Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"766e0a6a32174af09d1581f241921e33"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3459f658469b4692be3230567043a22e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"35bb6d46cf18443b9fcf5359dffdd676"}},"metadata":{}},{"name":"stdout","text":"Tokenizing Original Data...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Tokenizing Train:   0%|          | 0/1119999 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0574b161c2e14ca8af1008634dfb2804"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Tokenizing Val:   0%|          | 0/240001 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c9996d5c2fad4820a286c24ea94df531"}},"metadata":{}}],"execution_count":24},{"cell_type":"code","source":"def compute_metrics(pred):\n    labels = pred.label_ids\n    preds = pred.predictions.argmax(-1)\n    \n    acc = accuracy_score(labels, preds)\n    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='weighted')\n    \n    return {\n        \"accuracy\": acc,\n        \"f1\": f1,\n        \"precision\": precision,\n        \"recall\": recall\n    }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-09T17:24:58.114815Z","iopub.execute_input":"2026-02-09T17:24:58.115708Z","iopub.status.idle":"2026-02-09T17:24:58.121604Z","shell.execute_reply.started":"2026-02-09T17:24:58.115654Z","shell.execute_reply":"2026-02-09T17:24:58.120734Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"tqdm.pandas() \n\nmodel = AutoModelForSequenceClassification.from_pretrained(model_checkpoint, num_labels=3)\n\nargs = TrainingArguments(\n    output_dir=\"./results\",\n    eval_strategy=\"epoch\",  \n    save_strategy=\"epoch\",\n    learning_rate=2e-5,\n    per_device_train_batch_size=batch_size,\n    per_device_eval_batch_size=batch_size,\n    num_train_epochs=1,\n    weight_decay=0.01,\n    load_best_model_at_end=True,\n    logging_steps=50, \n    disable_tqdm=False,\n    report_to=\"none\" \n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-09T17:25:02.561259Z","iopub.execute_input":"2026-02-09T17:25:02.562192Z","iopub.status.idle":"2026-02-09T17:25:04.823019Z","shell.execute_reply.started":"2026-02-09T17:25:02.562151Z","shell.execute_reply":"2026-02-09T17:25:04.822090Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"71d002039028497a8126839de25058f0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"939d18ac478d49d5b7926aa918ac7ab0"}},"metadata":{}},{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}],"execution_count":21},{"cell_type":"code","source":"import os\nfrom optimum.onnxruntime import ORTModelForSequenceClassification\nfrom optimum.onnxruntime.configuration import AutoQuantizationConfig\nfrom optimum.onnxruntime import ORTQuantizer\n\ndef quantize_to_onnx(input_model_path, output_dir):\n    print(f\"üöÄ Starting conversion for: {input_model_path}\")\n    \n    model_onnx = ORTModelForSequenceClassification.from_pretrained(\n        input_model_path,\n        export=True\n    )\n\n    qconfig = AutoQuantizationConfig.arm64(is_static=False, per_channel=True)\n    \n    quantizer = ORTQuantizer.from_pretrained(model_onnx)\n    \n    quantizer.quantize(\n        save_dir=output_dir,\n        quantization_config=qconfig\n    )\n    \n    final_file = os.path.join(output_dir, \"model_quantized.onnx\")\n    size_mb = os.path.getsize(final_file) / (1024 * 1024)\n    print(f\"Model saved to: {final_file}\")\n    print(f\"Final Size: {size_mb:.2f} MB\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-09T17:25:25.024044Z","iopub.execute_input":"2026-02-09T17:25:25.024515Z","iopub.status.idle":"2026-02-09T17:25:35.630866Z","shell.execute_reply.started":"2026-02-09T17:25:25.024484Z","shell.execute_reply":"2026-02-09T17:25:35.629964Z"}},"outputs":[{"name":"stderr","text":"Multiple distributions found for package optimum. Picked distribution: optimum-onnx\n","output_type":"stream"}],"execution_count":22},{"cell_type":"code","source":"trainer = Trainer(\n    model=model,\n    args=args,\n    train_dataset=encoded_train,\n    eval_dataset=encoded_val,\n    tokenizer=tokenizer,\n    compute_metrics=compute_metrics,\n)\n\nprint(\"Training on Original Dataset...\")\ntrainer.train()\ntrainer.save_model(\"./distilbert_original\")\nquantize_to_onnx(\"./distilbert_original\", \"./onnx_quantized_original\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-09T17:29:24.147948Z","iopub.execute_input":"2026-02-09T17:29:24.148297Z","iopub.status.idle":"2026-02-09T18:36:42.727698Z","shell.execute_reply.started":"2026-02-09T17:29:24.148267Z","shell.execute_reply":"2026-02-09T18:36:42.726886Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_55/2728500336.py:1: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n  trainer = Trainer(\n","output_type":"stream"},{"name":"stdout","text":"Training on Original Dataset...\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='8750' max='8750' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [8750/8750 1:07:02, Epoch 1/1]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n      <th>F1</th>\n      <th>Precision</th>\n      <th>Recall</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.326500</td>\n      <td>0.321596</td>\n      <td>0.860755</td>\n      <td>0.860735</td>\n      <td>0.860956</td>\n      <td>0.860755</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"`torch_dtype` is deprecated! Use `dtype` instead!\n","output_type":"stream"},{"name":"stdout","text":"üöÄ Starting conversion for: ./distilbert_original\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/transformers/modeling_attn_mask_utils.py:196: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n  inverted_mask = torch.tensor(1.0, dtype=dtype) - expanded_mask\n","output_type":"stream"},{"name":"stdout","text":"Model saved to: ./onnx_quantized_original/model_quantized.onnx\nFinal Size: 64.45 MB\n","output_type":"stream"}],"execution_count":25},{"cell_type":"markdown","source":"### MiniLM","metadata":{}},{"cell_type":"code","source":"minilm_checkpints = 'microsoft/MiniLM-L12-H384-uncased'\n\ntokenizer = AutoTokenizer.from_pretrained(minilm_checkpints)\nmodel = AutoModelForSequenceClassification.from_pretrained(\n    minilm_checkpints, \n    num_labels=2,\n    id2label={0: \"Negative\", 1: \"Positive\"},\n    label2id={\"Negative\": 0, \"Positive\": 1}\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-09T19:05:58.336101Z","iopub.execute_input":"2026-02-09T19:05:58.336862Z","iopub.status.idle":"2026-02-09T19:06:01.635501Z","shell.execute_reply.started":"2026-02-09T19:05:58.336822Z","shell.execute_reply":"2026-02-09T19:06:01.634658Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/2.00 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"70122e14544f4af9bd1cb7d1804628d5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/385 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e78c76abae2949389c56fcb982fbd6df"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f2a10c5599dd4118bc7dbdc79853661f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"724e89cc473b4e71806e54054fe5741d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/133M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4d372a3a6d394091ba50bfdc13371ebe"}},"metadata":{}},{"name":"stderr","text":"Some weights of BertForSequenceClassification were not initialized from the model checkpoint at microsoft/MiniLM-L12-H384-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/133M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"314b592a9c754d70888206e201cfc2bc"}},"metadata":{}}],"execution_count":42},{"cell_type":"code","source":"args = TrainingArguments(\n    output_dir='/minilm',\n    num_train_epochs=3,\n    per_device_train_batch_size=32,\n    learning_rate=2e-5,\n    weight_decay=0.01,\n    eval_strategy=\"epoch\",\n    save_strategy=\"no\",\n    logging_steps=10,       \n    log_level=\"info\",        \n    report_to=\"none\",        \n    disable_tqdm=False       \n)\n\ntrainer = Trainer(\n    model=model,\n    args=args,\n    train_dataset=encoded_train,\n    eval_dataset=encoded_val,\n    compute_metrics=compute_metrics,\n)\n\nprint(\"Training MiniLM...\")\ntrainer.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-09T19:13:02.628326Z","iopub.execute_input":"2026-02-09T19:13:02.628660Z","iopub.status.idle":"2026-02-09T21:46:27.963805Z","shell.execute_reply.started":"2026-02-09T19:13:02.628630Z","shell.execute_reply":"2026-02-09T21:46:27.962850Z"}},"outputs":[{"name":"stderr","text":"The following columns in the Training set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: __index_level_0__, clean_text. If __index_level_0__, clean_text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n***** Running training *****\n  Num examples = 1,119,999\n  Num Epochs = 3\n  Instantaneous batch size per device = 32\n  Training with DataParallel so batch size has been adjusted to: 64\n  Total train batch size (w. parallel, distributed & accumulation) = 64\n  Gradient Accumulation steps = 1\n  Total optimization steps = 52,500\n  Number of trainable parameters = 33,360,770\n","output_type":"stream"},{"name":"stdout","text":"Training MiniLM...\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='52500' max='52500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [52500/52500 2:33:24, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n      <th>F1</th>\n      <th>Precision</th>\n      <th>Recall</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.301100</td>\n      <td>0.317349</td>\n      <td>0.863326</td>\n      <td>0.863309</td>\n      <td>0.863502</td>\n      <td>0.863326</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.336100</td>\n      <td>0.306950</td>\n      <td>0.867921</td>\n      <td>0.867909</td>\n      <td>0.868061</td>\n      <td>0.867921</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.297900</td>\n      <td>0.309074</td>\n      <td>0.869709</td>\n      <td>0.869693</td>\n      <td>0.869892</td>\n      <td>0.869709</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"The following columns in the Evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: __index_level_0__, clean_text. If __index_level_0__, clean_text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 240001\n  Batch size = 16\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\nThe following columns in the Evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: __index_level_0__, clean_text. If __index_level_0__, clean_text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 240001\n  Batch size = 16\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\nThe following columns in the Evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: __index_level_0__, clean_text. If __index_level_0__, clean_text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 240001\n  Batch size = 16\n\n\nTraining completed. Do not forget to share your model on huggingface.co/models =)\n\n\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_55/3527993695.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;31m# 4. Save the \"Brain\" (FP32)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Saving FP32 model to {output_dir}...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'output_dir' is not defined"],"ename":"NameError","evalue":"name 'output_dir' is not defined","output_type":"error"}],"execution_count":47},{"cell_type":"code","source":"print(f\"Saving FP32 model to {'./minilm'}...\")\ntrainer.save_model('./minilm')\ntokenizer.save_pretrained('./minilm')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-09T22:23:25.286840Z","iopub.execute_input":"2026-02-09T22:23:25.287166Z","iopub.status.idle":"2026-02-09T22:23:25.481732Z","shell.execute_reply.started":"2026-02-09T22:23:25.287140Z","shell.execute_reply":"2026-02-09T22:23:25.480985Z"}},"outputs":[{"name":"stderr","text":"Saving model checkpoint to ./minilm\nConfiguration saved in ./minilm/config.json\nModel weights saved in ./minilm/model.safetensors\ntokenizer config file saved in ./minilm/tokenizer_config.json\nSpecial tokens file saved in ./minilm/special_tokens_map.json\n","output_type":"stream"},{"name":"stdout","text":"Saving FP32 model to ./minilm...\n","output_type":"stream"},{"execution_count":50,"output_type":"execute_result","data":{"text/plain":"('./minilm/tokenizer_config.json',\n './minilm/special_tokens_map.json',\n './minilm/vocab.txt',\n './minilm/added_tokens.json',\n './minilm/tokenizer.json')"},"metadata":{}}],"execution_count":50},{"cell_type":"code","source":"import torch\nimport os\nfrom transformers import AutoModelForSequenceClassification, AutoTokenizer\n\ndef quantize_native_pytorch(input_path, output_path):\n    model = AutoModelForSequenceClassification.from_pretrained(input_path)\n    tokenizer = AutoTokenizer.from_pretrained(input_path)\n\n    quantized_model = torch.quantization.quantize_dynamic(\n        model, \n        {torch.nn.Linear},  \n        dtype=torch.qint8\n    )\n\n    os.makedirs(output_path, exist_ok=True)\n    \n    weights_path = os.path.join(output_path, \"quantized_weights.pt\")\n    torch.save(quantized_model.state_dict(), weights_path)\n\n    model.config.save_pretrained(output_path)\n    tokenizer.save_pretrained(output_path)\n    \n    size_mb = os.path.getsize(weights_path) / (1024 * 1024)\n    print(f\"\\nSuccess! Model reduced to: {size_mb:.2f} MB\")\n    print(f\"Saved to: {output_path}\")\n\nquantize_native_pytorch(\"./minilm\", \"./minilm_pytorch_quantized\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-09T22:31:37.054448Z","iopub.execute_input":"2026-02-09T22:31:37.055340Z","iopub.status.idle":"2026-02-09T22:31:37.624426Z","shell.execute_reply.started":"2026-02-09T22:31:37.055306Z","shell.execute_reply":"2026-02-09T22:31:37.623668Z"}},"outputs":[{"name":"stderr","text":"loading configuration file ./minilm/config.json\nModel config BertConfig {\n  \"architectures\": [\n    \"BertForSequenceClassification\"\n  ],\n  \"attention_probs_dropout_prob\": 0.1,\n  \"classifier_dropout\": null,\n  \"dtype\": \"float32\",\n  \"hidden_act\": \"gelu\",\n  \"hidden_dropout_prob\": 0.1,\n  \"hidden_size\": 384,\n  \"id2label\": {\n    \"0\": \"Negative\",\n    \"1\": \"Positive\"\n  },\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 1536,\n  \"label2id\": {\n    \"Negative\": 0,\n    \"Positive\": 1\n  },\n  \"layer_norm_eps\": 1e-12,\n  \"max_position_embeddings\": 512,\n  \"model_type\": \"bert\",\n  \"num_attention_heads\": 12,\n  \"num_hidden_layers\": 12,\n  \"pad_token_id\": 0,\n  \"position_embedding_type\": \"absolute\",\n  \"problem_type\": \"single_label_classification\",\n  \"transformers_version\": \"4.57.1\",\n  \"type_vocab_size\": 2,\n  \"use_cache\": true,\n  \"vocab_size\": 30522\n}\n\nloading weights file ./minilm/model.safetensors\nloading file vocab.txt\nloading file tokenizer.json\nloading file added_tokens.json\nloading file special_tokens_map.json\nloading file tokenizer_config.json\nloading file chat_template.jinja\n","output_type":"stream"},{"name":"stdout","text":"Loading model from ./minilm...\nQuantizing (Int8 Dynamic)...\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_55/754068341.py:15: DeprecationWarning: torch.ao.quantization is deprecated and will be removed in 2.10. \nFor migrations of users: \n1. Eager mode quantization (torch.ao.quantization.quantize, torch.ao.quantization.quantize_dynamic), please migrate to use torchao eager mode quantize_ API instead \n2. FX graph mode quantization (torch.ao.quantization.quantize_fx.prepare_fx,torch.ao.quantization.quantize_fx.convert_fx, please migrate to use torchao pt2e quantization API instead (prepare_pt2e, convert_pt2e) \n3. pt2e quantization has been migrated to torchao (https://github.com/pytorch/ao/tree/main/torchao/quantization/pt2e) \nsee https://github.com/pytorch/ao/issues/2259 for more details\n  quantized_model = torch.quantization.quantize_dynamic(\nConfiguration saved in ./minilm_pytorch_quantized/config.json\ntokenizer config file saved in ./minilm_pytorch_quantized/tokenizer_config.json\nSpecial tokens file saved in ./minilm_pytorch_quantized/special_tokens_map.json\n","output_type":"stream"},{"name":"stdout","text":"\n‚úÖ Success! Model reduced to: 66.22 MB\nSaved to: ./minilm_pytorch_quantized\n","output_type":"stream"}],"execution_count":52},{"cell_type":"code","source":"def predict(text, model, tokenizer):\n    # Fix 2: Change 'return_tensor' to 'return_tensors'\n    inputs = tokenizer(text, return_tensors = 'pt', truncation = True, max_length = 128)\n\n    with torch.no_grad():\n        output = model(**inputs)\n\n    logits = output.logits\n    probs = torch.nn.functional.softmax(logits, dim=-1)\n\n    pred_index = torch.argmax(probs, dim=-1).item()\n    confidence = probs[0][pred_index].item()\n\n    labels = {0: \"Negative\", 1: \"Positive\"}\n\n    return labels[pred_index], confidence","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-09T18:41:48.822420Z","iopub.execute_input":"2026-02-09T18:41:48.822761Z","iopub.status.idle":"2026-02-09T18:41:48.829012Z","shell.execute_reply.started":"2026-02-09T18:41:48.822735Z","shell.execute_reply":"2026-02-09T18:41:48.828216Z"}},"outputs":[],"execution_count":27},{"cell_type":"code","source":"import torch","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-09T18:45:42.471906Z","iopub.execute_input":"2026-02-09T18:45:42.472792Z","iopub.status.idle":"2026-02-09T18:45:42.476422Z","shell.execute_reply.started":"2026-02-09T18:45:42.472750Z","shell.execute_reply":"2026-02-09T18:45:42.475649Z"}},"outputs":[],"execution_count":30},{"cell_type":"code","source":"text1 = \"Let's put the meme aside, this is actually a banging song\"\nsentiment, score = predict(text1, model, tokenizer)\nprint(f\"Result: {sentiment} ({score:.1%})\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-09T18:45:53.092792Z","iopub.execute_input":"2026-02-09T18:45:53.093113Z","iopub.status.idle":"2026-02-09T18:45:53.212642Z","shell.execute_reply.started":"2026-02-09T18:45:53.093086Z","shell.execute_reply":"2026-02-09T18:45:53.211911Z"}},"outputs":[{"name":"stdout","text":"Result: Negative (68.4%)\nResult: Negative (66.3%)\nResult: Negative (66.0%)\nResult: Negative (67.1%)\nResult: Negative (67.3%)\nResult: Negative (67.5%)\nResult: Negative (65.6%)\nResult: Negative (68.4%)\n","output_type":"stream"}],"execution_count":32},{"cell_type":"code","source":"from transformers import pipeline\n\nclassifier = pipeline(\"sentiment-analysis\", model=\"/kaggle/working/minilm\", tokenizer=\"/kaggle/working/minilm\")\n\nprint(classifier(\"Let's put the meme aside, this is actually a banging song\"))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-09T22:28:25.721133Z","iopub.execute_input":"2026-02-09T22:28:25.721855Z","iopub.status.idle":"2026-02-09T22:28:26.014963Z","shell.execute_reply.started":"2026-02-09T22:28:25.721823Z","shell.execute_reply":"2026-02-09T22:28:26.014225Z"}},"outputs":[{"name":"stderr","text":"loading configuration file /kaggle/working/minilm/config.json\nModel config BertConfig {\n  \"architectures\": [\n    \"BertForSequenceClassification\"\n  ],\n  \"attention_probs_dropout_prob\": 0.1,\n  \"classifier_dropout\": null,\n  \"dtype\": \"float32\",\n  \"hidden_act\": \"gelu\",\n  \"hidden_dropout_prob\": 0.1,\n  \"hidden_size\": 384,\n  \"id2label\": {\n    \"0\": \"Negative\",\n    \"1\": \"Positive\"\n  },\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 1536,\n  \"label2id\": {\n    \"Negative\": 0,\n    \"Positive\": 1\n  },\n  \"layer_norm_eps\": 1e-12,\n  \"max_position_embeddings\": 512,\n  \"model_type\": \"bert\",\n  \"num_attention_heads\": 12,\n  \"num_hidden_layers\": 12,\n  \"pad_token_id\": 0,\n  \"position_embedding_type\": \"absolute\",\n  \"problem_type\": \"single_label_classification\",\n  \"transformers_version\": \"4.57.1\",\n  \"type_vocab_size\": 2,\n  \"use_cache\": true,\n  \"vocab_size\": 30522\n}\n\nloading configuration file /kaggle/working/minilm/config.json\nModel config BertConfig {\n  \"architectures\": [\n    \"BertForSequenceClassification\"\n  ],\n  \"attention_probs_dropout_prob\": 0.1,\n  \"classifier_dropout\": null,\n  \"dtype\": \"float32\",\n  \"hidden_act\": \"gelu\",\n  \"hidden_dropout_prob\": 0.1,\n  \"hidden_size\": 384,\n  \"id2label\": {\n    \"0\": \"Negative\",\n    \"1\": \"Positive\"\n  },\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 1536,\n  \"label2id\": {\n    \"Negative\": 0,\n    \"Positive\": 1\n  },\n  \"layer_norm_eps\": 1e-12,\n  \"max_position_embeddings\": 512,\n  \"model_type\": \"bert\",\n  \"num_attention_heads\": 12,\n  \"num_hidden_layers\": 12,\n  \"pad_token_id\": 0,\n  \"position_embedding_type\": \"absolute\",\n  \"problem_type\": \"single_label_classification\",\n  \"transformers_version\": \"4.57.1\",\n  \"type_vocab_size\": 2,\n  \"use_cache\": true,\n  \"vocab_size\": 30522\n}\n\nloading weights file /kaggle/working/minilm/model.safetensors\nWill use dtype=torch.float32 as defined in model's config object\nInstantiating BertForSequenceClassification model under default dtype torch.float32.\nloading file vocab.txt\nloading file tokenizer.json\nloading file added_tokens.json\nloading file special_tokens_map.json\nloading file tokenizer_config.json\nloading file chat_template.jinja\nDevice set to use cuda:0\n","output_type":"stream"},{"name":"stdout","text":"[{'label': 'Positive', 'score': 0.7343416810035706}]\n[{'label': 'Positive', 'score': 0.9673196077346802}]\n[{'label': 'Positive', 'score': 0.8110005259513855}]\n[{'label': 'Positive', 'score': 0.8651001453399658}]\n[{'label': 'Negative', 'score': 0.9204580187797546}]\n[{'label': 'Positive', 'score': 0.9287347197532654}]\n[{'label': 'Positive', 'score': 0.9687601923942566}]\n[{'label': 'Negative', 'score': 0.941748321056366}]\n","output_type":"stream"}],"execution_count":51},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}